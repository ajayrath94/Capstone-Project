{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bank-additional-full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fce04613334a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbank_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bank-additional-full.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bank-additional-full.csv'"
     ]
    }
   ],
   "source": [
    "bank_df = pd.read_csv('bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(bank_df.describe(), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Changing Name of Columns for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.rename(columns = {'campaign':'contacts_in_current_campaign','previous':'contacts_in_previous_campaign','default':'credit_default','y':'client_subscribed_term_deposit','loan':'has_personal_loan','poutcome':'previous_campaign_outcome'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catg_col=['job', 'marital', 'education', 'credit_default', 'housing',\n",
    "       'has_personal_loan','previous_campaign_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in catg_col:\n",
    "    print(i,bank_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.loc[(bank_df.job=='unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['job']=bank_df['job'].replace(['unknown'],['JOB_DUMMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['marital']=bank_df['marital'].replace(['unknown'],['MARITAL_DUMMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['education']=bank_df['education'].replace(['unknown'],['EDUCATION_DUMMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['credit_default']=bank_df['credit_default'].replace(['unknown'],['CREDIT_DEFAULT_DUMMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['housing']=bank_df['housing'].replace(['unknown'],['HOUSING_DUMMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['has_personal_loan']=bank_df['has_personal_loan'].replace(['unknown'],['HAS_PERSONAL_LOAN_DUMMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in catg_col:\n",
    "    print(i,bank_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in catg_col:\n",
    "       print(bank_df.groupby(i).count()['client_subscribed_term_deposit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring Age Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min age: ', bank_df['age'].max(),'Max age: ', \n",
    "      bank_df['age'].min(),'Null Values: ', \n",
    "      bank_df['age'].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(25, 10)\n",
    "sns.countplot(x = 'age', data = bank_df)\n",
    "ax.set_xlabel('Age', fontsize=25)\n",
    "ax.set_ylabel('Count', fontsize=25)\n",
    "ax.set_title('Age Count Distribution', fontsize=25)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\n",
    "sns.boxplot(x = 'age', data = bank_df, orient = 'v', ax = ax1)\n",
    "ax1.set_xlabel('People Age', fontsize=15)\n",
    "ax1.set_ylabel('Age', fontsize=15)\n",
    "ax1.set_title('Age Distribution', fontsize=15)\n",
    "ax1.tick_params(labelsize=15)\n",
    "\n",
    "sns.distplot(bank_df['age'], ax = ax2)\n",
    "sns.despine(ax = ax2)\n",
    "ax2.set_xlabel('Age', fontsize=15)\n",
    "ax2.set_ylabel('Occurence', fontsize=15)\n",
    "ax2.set_title('Age x Ocucurence', fontsize=15)\n",
    "ax2.tick_params(labelsize=15)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('1st Quartile: ', bank_df['age'].quantile(q = 0.25))\n",
    "print('2nd Quartile: ', bank_df['age'].quantile(q = 0.50))\n",
    "print('3rd Quartile: ', bank_df['age'].quantile(q = 0.75))\n",
    "print('4th Quartile: ', bank_df['age'].quantile(q = 1.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_outlier=bank_df['age'].quantile(q = 0.75) +1.5*(bank_df['age'].quantile(q = 0.75) - bank_df['age'].quantile(q = 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Age_Upper_Outlier Value',upper_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lower_outlier=bank_df['age'].quantile(q = 0.25) -1.5*(bank_df['age'].quantile(q = 0.75) - bank_df['age'].quantile(q = 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Age_Lower_Outlier Value',lower_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Converting Categorical data into numerical form using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "bank_df['contact']     = labelencoder_X.fit_transform(bank_df['contact']) \n",
    "bank_df['month']       = labelencoder_X.fit_transform(bank_df['month']) \n",
    "bank_df['day_of_week'] = labelencoder_X.fit_transform(bank_df['day_of_week']) \n",
    "bank_df['job']      = labelencoder_X.fit_transform(bank_df['job']) \n",
    "bank_df['marital']  = labelencoder_X.fit_transform(bank_df['marital']) \n",
    "bank_df['education']= labelencoder_X.fit_transform(bank_df['education']) \n",
    "bank_df['credit_default']  = labelencoder_X.fit_transform(bank_df['credit_default']) \n",
    "bank_df['housing']  = labelencoder_X.fit_transform(bank_df['housing']) \n",
    "bank_df['has_personal_loan']     = labelencoder_X.fit_transform(bank_df['has_personal_loan'])\n",
    "bank_df['client_subscribed_term_deposit']     = labelencoder_X.fit_transform(bank_df['client_subscribed_term_deposit'])\n",
    "bank_df['previous_campaign_outcome']     = labelencoder_X.fit_transform(bank_df['previous_campaign_outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing Train and Test split to create train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using K-folds cross validation to avoid over-fitting during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bank_df[bank_df.columns[0:-1]]\n",
    "y=bank_df[bank_df.columns[-1]]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using StandardScaler for normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "train_X = sc_X.fit_transform(train_X)\n",
    "valid_X = sc_X.transform(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression(max_iter=10000) \n",
    "logmodel.fit(train_X,train_y)\n",
    "logpred = logmodel.predict(valid_X)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_y, logpred))\n",
    "print(round(accuracy_score(valid_y, logpred),2)*100)\n",
    "Log_cv = (cross_val_score(logmodel, train_X, train_y, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valid_y, logpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(train_y == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(train_y == 0)))\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2)\n",
    "train_X_res, train_y_res = sm.fit_resample(train_X, train_y)\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(train_y_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(train_y_res == 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel2 = LogisticRegression(max_iter=20000) \n",
    "logmodel2.fit(train_X_res,train_y_res)\n",
    "logpred2 = logmodel2.predict(valid_X)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_y, logpred2))\n",
    "print(round(accuracy_score(valid_y, logpred2),2)*100)\n",
    "Log_cv = (cross_val_score(logmodel2, train_X_res, train_y_res, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valid_y, logpred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from dmba import plotDecisionTree, classificationSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassTree = DecisionTreeClassifier(max_depth=6, \n",
    "        min_impurity_decrease=0.001, min_samples_split=10)\n",
    "ClassTree.fit(train_X,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Tree with  Parameters')\n",
    "plotDecisionTree(ClassTree, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtres_pre = ClassTree.predict(valid_X)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_y,dtres_pre ))\n",
    "print(round(accuracy_score(valid_y, dtres_pre),2)*100)\n",
    "dtress_cv = (cross_val_score(ClassTree, train_X, train_y, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, dtres_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassTree2 = DecisionTreeClassifier(max_depth=10, \n",
    "        min_impurity_decrease=0.001, min_samples_split=10)\n",
    "ClassTree2.fit(train_X_res,train_y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Tree with  Parameters')\n",
    "plotDecisionTree(ClassTree2, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtres2_pre = ClassTree2.predict(valid_X)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_y,dtres2_pre ))\n",
    "print(round(accuracy_score(valid_y, dtres2_pre),2)*100)\n",
    "dtress_cv = (cross_val_score(ClassTree2, train_X_res, train_y_res, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, dtres2_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': list(range(2, 30)),  \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001], \n",
    "    'min_samples_split': list(range(5, 30)),\n",
    "}\n",
    "\n",
    "# Apply GridSearchCV() fucntion for various combinations of\n",
    "# DecisionTreeClassifier() improved parameters. \n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(), \n",
    "                param_grid, cv=5, n_jobs=-1)\n",
    "gridSearch.fit(train_X,train_y)\n",
    "\n",
    "# Display best improved paramenters of classification tree. \n",
    "print()\n",
    "print(f'Improved score:{gridSearch.best_score_:.4f}')\n",
    "print('Improved parameters: ', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': list(range(2, 30)),  \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001], \n",
    "    'min_samples_split': list(range(5, 30)),\n",
    "}\n",
    "\n",
    "# Apply GridSearchCV() fucntion for various combinations of\n",
    "# DecisionTreeClassifier() improved parameters. \n",
    "gridSearch2 = GridSearchCV(DecisionTreeClassifier(), \n",
    "                param_grid, cv=5, n_jobs=-1)\n",
    "gridSearch2.fit(train_X_res,train_y_res)\n",
    "\n",
    "# Display best improved paramenters of classification tree. \n",
    "print()\n",
    "print(f'Improved score:{gridSearch2.best_score_:.4f}')\n",
    "print('Improved parameters: ', gridSearch2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestClassTree = gridSearch.best_estimator_\n",
    "\n",
    "# Display classification tree based on improved parameters\n",
    "print('Best Classification Tree with Grid Search')\n",
    "plotDecisionTree(bestClassTree, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_nodes_grid = bestClassTree.tree_.node_count\n",
    "print('Number of nodes:', tree_nodes_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Summary with BestClassTree')\n",
    "classificationSummary(valid_y, bestClassTree.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, bestClassTree.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestClassTree2 = gridSearch2.best_estimator_\n",
    "\n",
    "# Display classification tree based on improved parameters\n",
    "print('Best Classification Tree with Grid Search')\n",
    "plotDecisionTree(bestClassTree2, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_nodes_grid2 = bestClassTree2.tree_.node_count\n",
    "print('Number of nodes:', tree_nodes_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Summary with BestClassTree')\n",
    "classificationSummary(valid_y, bestClassTree2.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, bestClassTree2.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, random_state=10)\n",
    "rf.fit(train_X,train_y)\n",
    "# Display number of nodes in Random Forest trees.\n",
    "n_nodes = rf.estimators_[0].tree_.node_count\n",
    "print('Number of Nodes in Tree in Random Forest:', n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Summary with Random Forest')\n",
    "classificationSummary(valid_y, rf.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, rf.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=500, random_state=10)\n",
    "rf2.fit(train_X_res,train_y_res)\n",
    "# Display number of nodes in Random Forest trees.\n",
    "n_nodes = rf2.estimators_[0].tree_.node_count\n",
    "print('Number of Nodes in Tree in Random Forest:', n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Summary with Random Forest')\n",
    "classificationSummary(valid_y, rf2.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, rf2.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = GradientBoostingClassifier(n_estimators=500, random_state=1)\n",
    "boost.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Data Summary with GradientBoost')\n",
    "classificationSummary(valid_y, boost.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, boost.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost2 = GradientBoostingClassifier(n_estimators=500, random_state=1)\n",
    "boost2.fit(train_X_res,train_y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Data Summary with GradientBoost')\n",
    "classificationSummary(valid_y, boost2.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, boost2.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_reg = MLPClassifier(hidden_layer_sizes=(9), max_iter=10000,\n",
    "                 solver='lbfgs', random_state=1,activation='logistic')\n",
    "neural_reg.fit(train_X,train_y)\n",
    "print('Final Intercepts for Train Data Neural Network Model')\n",
    "print(neural_reg.intercepts_)\n",
    "print()\n",
    "print('Network Weights for Train Data Neural Network Model')\n",
    "print(neural_reg.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Summary with Neural Network Classifier')\n",
    "classificationSummary(valid_y, neural_reg.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, neural_reg.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_reg2 = MLPClassifier(hidden_layer_sizes=(9), max_iter=10000,\n",
    "                 solver='lbfgs', random_state=1,activation='logistic')\n",
    "neural_reg2.fit(train_X_res,train_y_res)\n",
    "print('Final Intercepts for Train Data Neural Network Model')\n",
    "print(neural_reg2.intercepts_)\n",
    "print()\n",
    "print('Network Weights for Train Data Neural Network Model')\n",
    "print(neural_reg2.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Summary with Neural Network Classifier')\n",
    "classificationSummary(valid_y, neural_reg2.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, neural_reg2.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify grid search parameters. \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': list(range(2, 20)), \n",
    "}\n",
    "\n",
    "# Utilize GridSearchCV() to identify the best number \n",
    "# of nodes in the hidden layer. \n",
    "gridSearch_neural = GridSearchCV(MLPClassifier(solver='lbfgs', max_iter=10000, random_state=1), \n",
    "                          param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "gridSearch_neural.fit(train_X_res,train_y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best score and best parament value.\n",
    "print(f'Best score:{gridSearch_neural.best_score_:.4f}')\n",
    "print('Best parameter: ', gridSearch_neural.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_imp = MLPClassifier(hidden_layer_sizes=(17), max_iter=10000,\n",
    "                activation='logistic', solver='lbfgs', random_state=1)\n",
    "neural_imp.fit(train_X_res,train_y_res)\n",
    "\n",
    "# Display network structure with the final values of \n",
    "# intercepts (Theta) and weights (W).\n",
    "print('Final Intercepts for Improved Neural Network Model')\n",
    "print(neural_imp.intercepts_)\n",
    "\n",
    "print()\n",
    "print('Network Weights for Improved Neural Network Model')\n",
    "print(neural_imp.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Summary with Improved Neural Network Classifier')\n",
    "classificationSummary(valid_y, neural_imp.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y, neural_imp.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel2 = LogisticRegression(max_iter=20000) \n",
    "logmodel2.fit(train_X_res,train_y_res)\n",
    "logpred2 = logmodel2.predict(valid_X)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_y, logpred2))\n",
    "print(round(accuracy_score(valid_y, logpred2),2)*100)\n",
    "Log_cv = (cross_val_score(logmodel2, train_X_res, train_y_res, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmba import backward_elimination, forward_selection\n",
    "from dmba import adjusted_r2_score, AIC_score, BIC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    model.fit(X[variables],y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y_res, [train_y_res.mean()] * len(train_y_res), model, df=1)\n",
    "    return AIC_score(y, model.predict(X[variables]), model)\n",
    "\n",
    "\n",
    "best_model_fs, best_variables_fs = forward_selection(X.columns, \n",
    "                    train_model, score_model, verbose=True)\n",
    "\n",
    "print()\n",
    "print('Best Variables from Forward Selection Algorithm')\n",
    "print(best_variables_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_fs=['duration', 'pdays', 'euribor3m', 'credit_default', 'cons.conf.idx', 'has_personal_loan']\n",
    "X_fs = bank_df[predictor_fs]\n",
    "y_fs=bank_df[bank_df.columns[-1]]\n",
    "train_Xfs, valid_Xfs, train_yfs, valid_yfs = train_test_split(X_fs, y_fs, test_size=0.3, random_state=1)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_fs = LogisticRegression(max_iter=20000,penalty='l2', C=1e42, solver='liblinear') \n",
    "logmodel_fs.fit(train_Xfs,train_yfs)\n",
    "logpred_fs = logmodel_fs.predict(valid_Xfs)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_yfs, logpred_fs))\n",
    "print(round(accuracy_score(valid_yfs, logpred_fs),2)*100)\n",
    "Log_cv = (cross_val_score(logmodel_fs, train_Xfs, train_yfs, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valid_yfs, logpred_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(train_yfs == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(train_yfs == 0)))\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2)\n",
    "train_X_res_fs, train_y_res_fs = sm.fit_resample(train_Xfs, train_yfs)\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(train_y_res_fs == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(train_y_res_fs == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_fs2 = LogisticRegression(max_iter=20000,penalty='l2', C=1e42, solver='liblinear') \n",
    "logmodel_fs2.fit(train_X_res_fs,train_y_res_fs)\n",
    "logpred_fs2 = logmodel_fs2.predict(valid_Xfs)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_yfs, logpred_fs2))\n",
    "print(round(accuracy_score(valid_yfs, logpred_fs2),2)*100)\n",
    "Log_cv = (cross_val_score(logmodel_fs2, train_X_res_fs, train_y_res_fs, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valid_yfs, logpred_fs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(variables):\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    model.fit(X[variables],y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_model(model, variables):\n",
    "    return AIC_score(y, model.predict(X[variables]), model)\n",
    "\n",
    " \n",
    "best_model_be, best_variables_be = backward_elimination(X.columns, \n",
    "                        train_model, score_model, verbose=True)\n",
    "\n",
    "print()\n",
    "print('Best Variables from Backward Elimination Algorithm')\n",
    "print(best_variables_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_be=['age', 'job', 'marital', 'education', 'credit_default', 'contact', 'duration', 'contacts_in_current_campaign', 'pdays', 'contacts_in_previous_campaign', 'previous_campaign_outcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "X_be = bank_df[predictor_be]\n",
    "y_be=bank_df[bank_df.columns[-1]]\n",
    "train_Xbe, valid_Xbe, train_ybe, valid_ybe = train_test_split(X_be, y_be, test_size=0.3, random_state=1)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_be = LogisticRegression(max_iter=20000,penalty='l2', C=1e42, solver='liblinear') \n",
    "logmodel_be.fit(train_Xbe,train_ybe)\n",
    "logpred_be = logmodel_be.predict(valid_Xbe)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_ybe, logpred_be))\n",
    "print(round(accuracy_score(valid_ybe, logpred_be),2)*100)\n",
    "Log_cv = (cross_val_score(logmodel_be, train_Xbe, train_ybe, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valid_ybe, logpred_be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(train_ybe == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(train_ybe == 0)))\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2)\n",
    "train_X_res_be, train_y_res_be = sm.fit_resample(train_Xbe, train_ybe)\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(train_y_res_be == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(train_y_res_be == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel_be2 = LogisticRegression(max_iter=20000,penalty='l2', C=1e42, solver='liblinear') \n",
    "logmodel_be2.fit(train_X_res_be,train_y_res_be)\n",
    "logpred_be2 = logmodel_be2.predict(valid_Xbe)\n",
    "\n",
    "\n",
    "print(confusion_matrix(valid_ybe, logpred_be2))\n",
    "print(round(accuracy_score(valid_ybe, logpred_be2),2)*100)\n",
    "Log_cv = (cross_val_score(logmodel_be2, train_X_res_be, train_y_res_be, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valid_ybe, logpred_be2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
